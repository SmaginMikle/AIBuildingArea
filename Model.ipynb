{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eeabf2b-f314-4842-b002-f72514e807ad",
   "metadata": {},
   "source": [
    "Выполнять проектную работу буду на примере готового размеченного датасета со спутниковыми снимками:\n",
    "https://project.inria.fr/aerialimagelabeling/\n",
    "\n",
    "Для решения задачи семантической сегментации одного класса («площадь дома») на изображениях большого размера (5000×5000 пикселей) воспользуемся архитектурой U-Net — популярной архитектурой для сегментации, хорошо работающую со спутниковыми изображениями.\n",
    "В рамках работы пробовал ResNet18 и ResNet34. ResNet34 очень долго считает по времени без существенного \"выйгрыша\" по метрикам. Поэтому с целью ускорения вычислений и уменьшения платы яндекесу, но без существенной потери качества, итогововая модель рассчитана на ResNet18.\n",
    "\n",
    "Поскольку исходные изображения очень большие (5000×5000), прямая подача их в сеть невозможна из-за ограничений видеопамяти (арендую T4 16 GPU от Яндекса). Поэтому будем использовать тайлинг (разделение изображения на патчи), 512×512 с перекрытием (в рамках работы даннный параметр был отдельно подобран от 256 до 1024).\n",
    "\n",
    "Модель обучается на тайлах 512×512, что позволяет обрабатывать изображения любого размера.\n",
    "Маска в формате градаций серого, где 255 = дом, 0 = фон.\n",
    "Используется бинарная сегментация (num_classes=1 + BCEWithLogitsLoss).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489a324f-79f8-4dc9-9305-7f0a593ebe37",
   "metadata": {},
   "source": [
    "Стандартная модель U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8583da0-1d56-4689-b4c9-140a88636008",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T12:47:55.614910Z",
     "iopub.status.busy": "2026-01-09T12:47:55.614130Z",
     "iopub.status.idle": "2026-01-09T12:48:06.627146Z",
     "shell.execute_reply": "2026-01-09T12:48:06.626472Z",
     "shell.execute_reply.started": "2026-01-09T12:47:55.614879Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c29fd5b4-ea95-4b23-8003-9b5f5b545e5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T12:48:06.629104Z",
     "iopub.status.busy": "2026-01-09T12:48:06.628361Z",
     "iopub.status.idle": "2026-01-09T12:48:06.761677Z",
     "shell.execute_reply": "2026-01-09T12:48:06.760979Z",
     "shell.execute_reply.started": "2026-01-09T12:48:06.629072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используемое устройство: cuda\n",
      "   GPU: NVIDIA L4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Устройство\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Используемое устройство: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36dfa626-abd8-4b18-ada2-3e866bfdbb3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T14:20:31.292633Z",
     "iopub.status.busy": "2026-01-09T14:20:31.290936Z",
     "iopub.status.idle": "2026-01-09T17:09:33.657643Z",
     "shell.execute_reply": "2026-01-09T17:09:33.656909Z",
     "shell.execute_reply.started": "2026-01-09T14:20:31.292560Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Запуск обучения модели: 2026-01-09 14:20:31\n",
      "============================================================\n",
      "Папка с изображениями: /home/jupyter/project/Data/train/images\n",
      "Папка с масками:       /home/jupyter/project/Data/train/masks\n",
      " Найдено изображений: 180\n",
      "Найдено пар изображение/маска: 180\n",
      "Обучающих примеров: 144\n",
      "Валидационных примеров: 36\n",
      "Создание датасетов...\n",
      "Общее количество тайлов (train): 14400\n",
      "Общее количество тайлов (val):   3600\n",
      " Используемое устройство: cuda\n",
      "   GPU: NVIDIA L4\n",
      "Инициализация модели U-Net с ResNet14 backbone...\n",
      "   Всего параметров: 14,342,337\n",
      "   Обучаемых параметров: 14,342,337\n",
      "\n",
      "Начало обучения...\n",
      "\n",
      "Batch 51: Data loading: 0.005s | GPU compute: 0.193s | train_iou: 0.143 | train_acc: 0.875 | \n",
      "Batch 101: Data loading: 0.005s | GPU compute: 0.193s | train_iou: 0.143 | train_acc: 0.835 | \n",
      "Batch 151: Data loading: 0.004s | GPU compute: 0.193s | train_iou: 0.119 | train_acc: 0.811 | \n",
      "Batch 201: Data loading: 0.004s | GPU compute: 0.198s | train_iou: 0.236 | train_acc: 0.838 | \n",
      "Batch 251: Data loading: 0.005s | GPU compute: 0.193s | train_iou: 0.319 | train_acc: 0.853 | \n",
      "Batch 301: Data loading: 0.005s | GPU compute: 0.194s | train_iou: 0.379 | train_acc: 0.868 | \n",
      "Batch 351: Data loading: 0.004s | GPU compute: 0.194s | train_iou: 0.423 | train_acc: 0.876 | \n",
      "Batch 401: Data loading: 0.004s | GPU compute: 0.197s | train_iou: 0.461 | train_acc: 0.881 | \n",
      "Batch 451: Data loading: 0.005s | GPU compute: 0.193s | train_iou: 0.491 | train_acc: 0.889 | \n",
      "Batch 501: Data loading: 0.005s | GPU compute: 0.194s | train_iou: 0.506 | train_acc: 0.893 | \n",
      "Batch 551: Data loading: 0.004s | GPU compute: 0.193s | train_iou: 0.521 | train_acc: 0.897 | \n",
      "Batch 601: Data loading: 0.004s | GPU compute: 0.195s | train_iou: 0.538 | train_acc: 0.901 | \n",
      "Batch 651: Data loading: 0.005s | GPU compute: 0.193s | train_iou: 0.556 | train_acc: 0.905 | \n",
      "Batch 701: Data loading: 0.005s | GPU compute: 0.193s | train_iou: 0.568 | train_acc: 0.908 | \n",
      "Batch 751: Data loading: 0.005s | GPU compute: 0.193s | train_iou: 0.576 | train_acc: 0.911 | \n",
      "Batch 801: Data loading: 0.004s | GPU compute: 0.198s | train_iou: 0.587 | train_acc: 0.915 | \n",
      "Batch 851: Data loading: 0.005s | GPU compute: 0.193s | train_iou: 0.593 | train_acc: 0.917 | \n",
      "Batch 901: Data loading: 0.005s | GPU compute: 0.194s | train_iou: 0.592 | train_acc: 0.919 | \n",
      "Batch 951: Data loading: 0.004s | GPU compute: 0.193s | train_iou: 0.594 | train_acc: 0.919 | \n",
      "Batch 1001: Data loading: 0.004s | GPU compute: 0.197s | train_iou: 0.601 | train_acc: 0.921 | \n",
      "\n",
      " Среднее за батч:\n",
      "   Загрузка данных: 0.005 сек\n",
      "   Вычисления на GPU: 0.194 сек\n",
      "   GPU utilization: ~97.7%\n",
      "GPU — основное время\n",
      "Epoch 01/10 | Train Loss: 0.1827 | Train IoU: 0.6012 | Train Acc: 0.9207 | Val Loss: 0.1201 | Val IoU: 0.6980 | Val Acc: 0.9535 | Time: 2512.1s\n",
      "Batch 51: Data loading: 0.004s | GPU compute: 0.193s | train_iou: 0.764 | train_acc: 0.953 | \n",
      "Batch 101: Data loading: 0.004s | GPU compute: 0.195s | train_iou: 0.716 | train_acc: 0.960 | \n",
      "Batch 151: Data loading: 0.004s | GPU compute: 0.194s | train_iou: 0.724 | train_acc: 0.957 | \n",
      "Batch 201: Data loading: 0.004s | GPU compute: 0.193s | train_iou: 0.702 | train_acc: 0.955 | \n",
      "Batch 251: Data loading: 0.004s | GPU compute: 0.193s | train_iou: 0.705 | train_acc: 0.951 | \n",
      "Batch 301: Data loading: 0.004s | GPU compute: 0.193s | train_iou: 0.693 | train_acc: 0.950 | \n",
      "Batch 351: Data loading: 0.004s | GPU compute: 0.193s | train_iou: 0.694 | train_acc: 0.946 | \n",
      "Batch 401: Data loading: 0.005s | GPU compute: 0.193s | train_iou: 0.685 | train_acc: 0.948 | \n",
      "Batch 451: Data loading: 0.004s | GPU compute: 0.194s | train_iou: 0.697 | train_acc: 0.947 | \n",
      "Batch 501: Data loading: 0.005s | GPU compute: 0.194s | train_iou: 0.682 | train_acc: 0.949 | \n",
      "Batch 551: Data loading: 0.005s | GPU compute: 0.194s | train_iou: 0.688 | train_acc: 0.949 | \n",
      "Batch 601: Data loading: 0.005s | GPU compute: 0.191s | train_iou: 0.692 | train_acc: 0.950 | \n",
      "Batch 651: Data loading: 0.004s | GPU compute: 0.194s | train_iou: 0.690 | train_acc: 0.950 | \n",
      "Batch 701: Data loading: 0.004s | GPU compute: 0.194s | train_iou: 0.689 | train_acc: 0.950 | \n",
      "Batch 751: Data loading: 0.005s | GPU compute: 0.192s | train_iou: 0.696 | train_acc: 0.952 | \n",
      "Batch 801: Data loading: 0.005s | GPU compute: 0.193s | train_iou: 0.687 | train_acc: 0.953 | \n",
      "Batch 851: Data loading: 0.004s | GPU compute: 0.193s | train_iou: 0.693 | train_acc: 0.954 | \n",
      "Batch 901: Data loading: 0.004s | GPU compute: 0.193s | train_iou: 0.696 | train_acc: 0.955 | \n",
      "Batch 951: Data loading: 0.005s | GPU compute: 0.194s | train_iou: 0.699 | train_acc: 0.955 | \n",
      "Batch 1001: Data loading: 0.005s | GPU compute: 0.195s | train_iou: 0.698 | train_acc: 0.955 | \n",
      "\n",
      " Среднее за батч:\n",
      "   Загрузка данных: 0.005 сек\n",
      "   Вычисления на GPU: 0.194 сек\n",
      "   GPU utilization: ~97.7%\n",
      "GPU — основное время\n",
      "Epoch 02/10 | Train Loss: 0.1167 | Train IoU: 0.6978 | Train Acc: 0.9554 | Val Loss: 0.1105 | Val IoU: 0.7217 | Val Acc: 0.9579 | Time: 2527.2s\n",
      "Batch 51: Data loading: 0.005s | GPU compute: 0.194s | train_iou: 0.701 | train_acc: 0.954 | \n",
      "Batch 101: Data loading: 0.004s | GPU compute: 0.194s | train_iou: 0.744 | train_acc: 0.953 | \n",
      "Batch 151: Data loading: 0.004s | GPU compute: 0.198s | train_iou: 0.756 | train_acc: 0.957 | \n",
      "Batch 201: Data loading: 0.005s | GPU compute: 0.194s | train_iou: 0.762 | train_acc: 0.963 | \n",
      "Batch 251: Data loading: 0.005s | GPU compute: 0.194s | train_iou: 0.771 | train_acc: 0.964 | \n",
      "Batch 301: Data loading: 0.005s | GPU compute: 0.195s | train_iou: 0.760 | train_acc: 0.963 | \n",
      "Batch 351: Data loading: 0.004s | GPU compute: 0.193s | train_iou: 0.757 | train_acc: 0.961 | \n",
      "Batch 401: Data loading: 0.005s | GPU compute: 0.192s | train_iou: 0.753 | train_acc: 0.960 | \n",
      "Batch 451: Data loading: 0.005s | GPU compute: 0.193s | train_iou: 0.753 | train_acc: 0.962 | \n",
      "Batch 501: Data loading: 0.004s | GPU compute: 0.194s | train_iou: 0.741 | train_acc: 0.959 | \n",
      "Batch 551: Data loading: 0.005s | GPU compute: 0.198s | train_iou: 0.744 | train_acc: 0.959 | \n",
      "Batch 601: Data loading: 0.005s | GPU compute: 0.194s | train_iou: 0.745 | train_acc: 0.960 | \n",
      "Batch 651: Data loading: 0.005s | GPU compute: 0.193s | train_iou: 0.737 | train_acc: 0.961 | \n",
      "Batch 701: Data loading: 0.004s | GPU compute: 0.193s | train_iou: 0.730 | train_acc: 0.961 | \n",
      "Batch 751: Data loading: 0.004s | GPU compute: 0.196s | train_iou: 0.732 | train_acc: 0.960 | \n",
      "Batch 801: Data loading: 0.004s | GPU compute: 0.193s | train_iou: 0.735 | train_acc: 0.960 | \n",
      "Batch 851: Data loading: 0.005s | GPU compute: 0.194s | train_iou: 0.737 | train_acc: 0.960 | \n",
      "Batch 901: Data loading: 0.005s | GPU compute: 0.193s | train_iou: 0.741 | train_acc: 0.960 | \n",
      "Batch 951: Data loading: 0.004s | GPU compute: 0.195s | train_iou: 0.743 | train_acc: 0.959 | \n",
      "Batch 1001: Data loading: 0.004s | GPU compute: 0.194s | train_iou: 0.741 | train_acc: 0.960 | \n",
      "\n",
      " Среднее за батч:\n",
      "   Загрузка данных: 0.005 сек\n",
      "   Вычисления на GPU: 0.194 сек\n",
      "   GPU utilization: ~97.7%\n",
      "GPU — основное время\n",
      "Epoch 03/10 | Train Loss: 0.1050 | Train IoU: 0.7408 | Train Acc: 0.9603 | Val Loss: 0.1168 | Val IoU: 0.7048 | Val Acc: 0.9553 | Time: 2525.9s\n",
      "Batch 51: Data loading: 0.004s | GPU compute: 0.193s | train_iou: 0.760 | train_acc: 0.956 | \n",
      "Batch 101: Data loading: 0.004s | GPU compute: 0.194s | train_iou: 0.790 | train_acc: 0.966 | \n",
      "Batch 151: Data loading: 0.004s | GPU compute: 0.193s | train_iou: 0.782 | train_acc: 0.965 | \n",
      "Batch 201: Data loading: 0.004s | GPU compute: 0.193s | train_iou: 0.778 | train_acc: 0.964 | \n",
      "Batch 251: Data loading: 0.004s | GPU compute: 0.193s | train_iou: 0.784 | train_acc: 0.962 | \n",
      "Batch 301: Data loading: 0.004s | GPU compute: 0.194s | train_iou: 0.775 | train_acc: 0.963 | \n",
      "Batch 351: Data loading: 0.004s | GPU compute: 0.195s | train_iou: 0.760 | train_acc: 0.960 | \n",
      "Batch 401: Data loading: 0.005s | GPU compute: 0.193s | train_iou: 0.743 | train_acc: 0.961 | \n",
      "Batch 451: Data loading: 0.004s | GPU compute: 0.192s | train_iou: 0.742 | train_acc: 0.961 | \n",
      "Batch 501: Data loading: 0.005s | GPU compute: 0.193s | train_iou: 0.740 | train_acc: 0.961 | \n",
      "Batch 551: Data loading: 0.004s | GPU compute: 0.196s | train_iou: 0.737 | train_acc: 0.959 | \n",
      "Batch 601: Data loading: 0.004s | GPU compute: 0.193s | train_iou: 0.731 | train_acc: 0.961 | \n",
      "Batch 651: Data loading: 0.004s | GPU compute: 0.192s | train_iou: 0.732 | train_acc: 0.961 | \n",
      "Batch 701: Data loading: 0.004s | GPU compute: 0.197s | train_iou: 0.725 | train_acc: 0.960 | \n",
      "Batch 751: Data loading: 0.004s | GPU compute: 0.195s | train_iou: 0.723 | train_acc: 0.960 | \n",
      "Batch 801: Data loading: 0.004s | GPU compute: 0.194s | train_iou: 0.722 | train_acc: 0.959 | \n",
      "Batch 851: Data loading: 0.004s | GPU compute: 0.196s | train_iou: 0.721 | train_acc: 0.957 | \n",
      "Batch 901: Data loading: 0.005s | GPU compute: 0.195s | train_iou: 0.721 | train_acc: 0.957 | \n",
      "Batch 951: Data loading: 0.004s | GPU compute: 0.195s | train_iou: 0.722 | train_acc: 0.957 | \n",
      "Batch 1001: Data loading: 0.005s | GPU compute: 0.194s | train_iou: 0.728 | train_acc: 0.958 | \n",
      "\n",
      " Среднее за батч:\n",
      "   Загрузка данных: 0.005 сек\n",
      "   Вычисления на GPU: 0.194 сек\n",
      "   GPU utilization: ~97.7%\n",
      "GPU — основное время\n",
      "Epoch 04/10 | Train Loss: 0.0964 | Train IoU: 0.7278 | Train Acc: 0.9576 | Val Loss: 0.1022 | Val IoU: 0.7515 | Val Acc: 0.9619 | Time: 2550.6s\n",
      "\n",
      "Модель успешно сохранена: /home/jupyter/project/house_segmentation_model.pth\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 1. Определение модели (U-Net на базе ResNet18 backbone)\n",
    "# ----------------------------\n",
    "\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "class UNetResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super().__init__()\n",
    "        weights = ResNet18_Weights.IMAGENET1K_V1\n",
    "        encoder = resnet18(weights=weights)\n",
    "\n",
    "        # Сохраняем все нужные уровни\n",
    "        self.enc0 = nn.Sequential(encoder.conv1, encoder.bn1, encoder.relu)  # до maxpool → H/2\n",
    "        self.pool = encoder.maxpool  # → H/4\n",
    "        self.enc1 = encoder.layer1   # → H/4\n",
    "        self.enc2 = encoder.layer2   # → H/8\n",
    "        self.enc3 = encoder.layer3   # → H/16\n",
    "        self.enc4 = encoder.layer4   # → H/32\n",
    "\n",
    "        # Decoder\n",
    "        self.upconv4 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)  # H/16\n",
    "        self.decoder4 = self._conv_block(512, 256)\n",
    "\n",
    "        self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)  # H/8\n",
    "        self.decoder3 = self._conv_block(256, 128)\n",
    "\n",
    "        self.upconv2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)   # H/4\n",
    "        self.decoder2 = self._conv_block(128, 64)\n",
    "\n",
    "        self.upconv1 = nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2)    # H/2\n",
    "        self.decoder1 = self._conv_block(128, 64)\n",
    "\n",
    "        self.upconv0 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)    # H\n",
    "        self.decoder0 = self._conv_block(32, 32)  # enc0 имеет 64 канала, но мы используем только часть\n",
    "\n",
    "        self.final = nn.Conv2d(32, num_classes, kernel_size=1)\n",
    "\n",
    "    def _conv_block(self, in_ch, out_ch):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e0 = self.enc0(x)       # H/2, 64\n",
    "        x = self.pool(e0)       # H/4\n",
    "        e1 = self.enc1(x)       # H/4, 64\n",
    "        e2 = self.enc2(e1)      # H/8, 128\n",
    "        e3 = self.enc3(e2)      # H/16, 256\n",
    "        e4 = self.enc4(e3)      # H/32, 512\n",
    "\n",
    "        # Decoder\n",
    "        d4 = self.upconv4(e4)               # H/16, 256\n",
    "        d4 = torch.cat([d4, e3], dim=1)     # 256+256 = 512\n",
    "        d4 = self.decoder4(d4)\n",
    "\n",
    "        d3 = self.upconv3(d4)               # H/8, 128\n",
    "        d3 = torch.cat([d3, e2], dim=1)     # 128+128 = 256\n",
    "        d3 = self.decoder3(d3)\n",
    "\n",
    "        d2 = self.upconv2(d3)               # H/4, 64\n",
    "        d2 = torch.cat([d2, e1], dim=1)     # 64+64 = 128\n",
    "        d2 = self.decoder2(d2)\n",
    "\n",
    "        d1 = self.upconv1(d2)               # H/2, 64\n",
    "        d1 = torch.cat([d1, e0], dim=1)     # 64+64 = 128 ← теперь размеры совпадают!\n",
    "        d1 = self.decoder1(d1)\n",
    "\n",
    "        d0 = self.upconv0(d1)               # H, 32\n",
    "        d0 = self.decoder0(d0)\n",
    "\n",
    "        out = self.final(d0)\n",
    "        return out\n",
    "    \n",
    "# ----------------------------\n",
    "# 2. Загрузчик данных (разбивает большие изображения на тайлы)\n",
    "# ----------------------------\n",
    "\n",
    "class LargeImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, tile_size=512):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.tile_size = tile_size\n",
    "        self.tiles = self._build_tile_list()\n",
    "\n",
    "    def _build_tile_list(self):\n",
    "        tiles = []\n",
    "        for i, (img_path, mask_path) in enumerate(zip(self.image_paths, self.mask_paths)):\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if mask is None:\n",
    "                raise IOError(f\"Не удалось загрузить маску: {mask_path}\")\n",
    "            h, w = mask.shape\n",
    "            for y in range(0, h, self.tile_size):\n",
    "                for x in range(0, w, self.tile_size):\n",
    "                    tiles.append((i, y, x))\n",
    "        return tiles\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tiles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_idx, y, x = self.tiles[idx]\n",
    "        # Читаем изображение и маску КАЖДЫЙ РАЗ\n",
    "        img = cv2.imread(self.image_paths[img_idx])\n",
    "        mask = cv2.imread(self.mask_paths[img_idx], cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if img is None or mask is None:\n",
    "            raise IOError(f\"Ошибка чтения: {self.image_paths[img_idx]} или маска\")\n",
    "\n",
    "        h, w = img.shape[:2]\n",
    "        x_end = min(x + self.tile_size, w)\n",
    "        y_end = min(y + self.tile_size, h)\n",
    "\n",
    "        tile_img = img[y:y_end, x:x_end]\n",
    "        tile_mask = mask[y:y_end, x:x_end]\n",
    "\n",
    "        pad_h = self.tile_size - tile_img.shape[0]\n",
    "        pad_w = self.tile_size - tile_img.shape[1]\n",
    "        tile_img = np.pad(tile_img, ((0, pad_h), (0, pad_w), (0, 0)), mode='constant')\n",
    "        tile_mask = np.pad(tile_mask, ((0, pad_h), (0, pad_w)), mode='constant')\n",
    "\n",
    "        tile_img = torch.from_numpy(tile_img).permute(2, 0, 1).float() / 255.0\n",
    "        tile_mask = torch.from_numpy(tile_mask).unsqueeze(0).float() / 255.0\n",
    "\n",
    "        return tile_img, tile_mask\n",
    "    \n",
    "# ----------------------------\n",
    "# 3. Обучение\n",
    "# ----------------------------\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def calculate_iou(pred, target, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Вычисляет IoU для бинарной сегментации.\n",
    "    pred: Tensor [B, 1, H, W] — логиты или вероятности\n",
    "    target: Tensor [B, 1, H, W] — маски (0 или 1)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        pred = torch.sigmoid(pred)  # преобразуем логиты в вероятности\n",
    "        pred = (pred > threshold).float()\n",
    "        target = (target > 0.5).float()  # на случай, если маска не бинарная\n",
    "\n",
    "        intersection = (pred * target).sum(dim=(1, 2, 3))\n",
    "        union = (pred + target - pred * target).sum(dim=(1, 2, 3))\n",
    "        iou = (intersection + 1e-6) / (union + 1e-6)  # eps для стабильности\n",
    "        return iou.mean().item()\n",
    "\n",
    "def calculate_accuracy(pred, target, threshold=0.5):\n",
    "    \"\"\"Вычисляет точность (pixel accuracy)\"\"\"\n",
    "    with torch.no_grad():\n",
    "        pred = torch.sigmoid(pred)\n",
    "        pred = (pred > threshold).float()\n",
    "        target = (target > 0.5).float()\n",
    "        correct = (pred == target).float().sum()\n",
    "        total = target.numel()\n",
    "        return (correct / total).item()\n",
    "\n",
    "def calculate_iou_gpu(pred, target, threshold=0.5):\n",
    "    with torch.no_grad():\n",
    "        pred = (torch.sigmoid(pred) > threshold).float()\n",
    "        target = (target > 0.5).float()\n",
    "        intersection = (pred * target).sum(dim=(1, 2, 3))\n",
    "        union = (pred + target - pred * target).sum(dim=(1, 2, 3))\n",
    "        iou = (intersection + 1e-6) / (union + 1e-6)\n",
    "        return iou.sum()  # возвращаем сумму, а не среднее\n",
    "\n",
    "def calculate_accuracy_gpu(pred, target, threshold=0.5):\n",
    "    with torch.no_grad():\n",
    "        pred = (torch.sigmoid(pred) > threshold).float()\n",
    "        target = (target > 0.5).float()\n",
    "        correct = (pred == target).float().sum()\n",
    "        return correct  # возвращаем число правильных пикселей\n",
    "    \n",
    "def train_model():\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Запуск обучения модели: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    image_dir = \"Data/train/images\"\n",
    "    mask_dir = \"Data/train/masks\"\n",
    "\n",
    "    print(f\"Папка с изображениями: {os.path.abspath(image_dir)}\")\n",
    "    print(f\"Папка с масками:       {os.path.abspath(mask_dir)}\")\n",
    "\n",
    "    image_extensions = {\".jpg\", \".jpeg\", \".png\", \".tif\", \".tiff\"}\n",
    "    mask_extensions = {\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\"}\n",
    "\n",
    "    image_files = []\n",
    "    for ext in image_extensions:\n",
    "        image_files.extend(glob.glob(os.path.join(image_dir, f\"*{ext}\")))\n",
    "        image_files.extend(glob.glob(os.path.join(image_dir, f\"*{ext.upper()}\")))\n",
    "    image_files = sorted(list(set(image_files)))\n",
    "\n",
    "    if not image_files:\n",
    "        raise FileNotFoundError(f\"Не найдено изображений в {image_dir}\")\n",
    "\n",
    "    print(f\" Найдено изображений: {len(image_files)}\")\n",
    "\n",
    "    image_paths = []\n",
    "    mask_paths = []\n",
    "    for img_path in image_files:\n",
    "        img_name = Path(img_path).stem\n",
    "        mask_found = False\n",
    "        for ext in mask_extensions:\n",
    "            for candidate in [ext, ext.upper()]:\n",
    "                mask_path = os.path.join(mask_dir, img_name + candidate)\n",
    "                if os.path.exists(mask_path):\n",
    "                    image_paths.append(img_path)\n",
    "                    mask_paths.append(mask_path)\n",
    "                    mask_found = True\n",
    "                    break\n",
    "            if mask_found:\n",
    "                break\n",
    "        if not mask_found:\n",
    "            print(f\" Пропущено (маска не найдена): {os.path.basename(img_path)}\")\n",
    "\n",
    "    if not image_paths:\n",
    "        raise FileNotFoundError(\"Не найдено ни одной пары изображение/маска\")\n",
    "\n",
    "    print(f\"Найдено пар изображение/маска: {len(image_paths)}\")\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        image_paths, mask_paths, test_size=0.2, random_state=42\n",
    "    )\n",
    "    print(f\"Обучающих примеров: {len(X_train)}\")\n",
    "    print(f\"Валидационных примеров: {len(X_val)}\")\n",
    "\n",
    "    print(\"Создание датасетов...\")\n",
    "    train_dataset = LargeImageDataset(X_train, y_train, tile_size=512)\n",
    "    val_dataset = LargeImageDataset(X_val, y_val, tile_size=512)\n",
    "    print(f\"Общее количество тайлов (train): {len(train_dataset)}\")\n",
    "    print(f\"Общее количество тайлов (val):   {len(val_dataset)}\")\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=14, shuffle=True, num_workers=8, pin_memory=True, prefetch_factor=2, persistent_workers=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=14, shuffle=False, num_workers=8, pin_memory=True, prefetch_factor=2, persistent_workers=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\" Используемое устройство: {device}\")\n",
    "    if device.type == \"cuda\":\n",
    "        print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "    print(\"Инициализация модели U-Net с ResNet14 backbone...\")\n",
    "    model = UNetResNet18(num_classes=1).to(device)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"   Всего параметров: {total_params:,}\")\n",
    "    print(f\"   Обучаемых параметров: {trainable_params:,}\")\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    print(\"\\nНачало обучения...\\n\")\n",
    "\n",
    "    # --- Основной цикл обучения с валидацией ---\n",
    "    \n",
    "    # --- Профилирование батчей ---\n",
    "    data_loading_times = []\n",
    "    gpu_compute_times = []\n",
    "    log_every = 50  # считать метрики каждые 20 батчей\n",
    "    \n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    for epoch in range(4):\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        # ===== Обучение =====\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_iou = 0.0\n",
    "        train_acc = 0.0\n",
    "        batch_idx = 0\n",
    "        num_metric_batches = 0\n",
    "        for images, masks in train_loader:\n",
    "            \n",
    "            batch_idx = batch_idx + 1\n",
    "            # Время загрузки данных (CPU)\n",
    "            start_data = time.time()\n",
    "            images, masks = images.to(device, non_blocking=True), masks.to(device, non_blocking=True)\n",
    "            torch.cuda.synchronize()  # ждём, пока данные попадут на GPU\n",
    "            data_time = time.time() - start_data\n",
    "            \n",
    "            # Время вычислений на GPU\n",
    "            start_gpu = time.time()\n",
    "            optimizer.zero_grad()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "           \n",
    "            torch.cuda.synchronize()  # синхронизация GPU     \n",
    "            gpu_time = time.time() - start_gpu\n",
    "    \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            data_loading_times.append(data_time)\n",
    "            gpu_compute_times.append(gpu_time)\n",
    "\n",
    "            if batch_idx  % log_every == 0:\n",
    "                train_iou += calculate_iou(outputs, masks)\n",
    "                train_acc += calculate_accuracy(outputs, masks)\n",
    "                num_metric_batches += 1\n",
    "                print(f\"Batch {batch_idx+1}: \"\n",
    "                      f\"Data loading: {data_time:.3f}s | \"\n",
    "                      f\"GPU compute: {gpu_time:.3f}s | \"\n",
    "                      f\"train_iou: {train_iou / num_metric_batches:.3f} | \"\n",
    "                      f\"train_acc: {train_acc / num_metric_batches:.3f} | \"\n",
    "                     )            \n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_train_iou = train_iou / num_metric_batches\n",
    "        avg_train_acc = train_acc / num_metric_batches\n",
    "        \n",
    "        avg_data = sum(data_loading_times) / len(data_loading_times)\n",
    "        avg_gpu = sum(gpu_compute_times) / len(gpu_compute_times)\n",
    "\n",
    "        print(f\"\\n Среднее за батч:\")\n",
    "        print(f\"   Загрузка данных: {avg_data:.3f} сек\")\n",
    "        print(f\"   Вычисления на GPU: {avg_gpu:.3f} сек\")\n",
    "        print(f\"   GPU utilization: ~{avg_gpu / (avg_data + avg_gpu) * 100:.1f}%\")\n",
    "\n",
    "        if avg_data > avg_gpu:\n",
    "            print(\"УЗКОЕ МЕСТО: загрузка данных (CPU/DataLoader)\")\n",
    "        else:\n",
    "            print(\"GPU — основное время\")        \n",
    "\n",
    "        # ===== Валидация =====\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_iou = 0.0\n",
    "        val_acc = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                val_iou += calculate_iou(outputs, masks)\n",
    "                val_acc += calculate_accuracy(outputs, masks)\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_iou = val_iou / len(val_loader)\n",
    "        avg_val_acc = val_acc / len(val_loader)\n",
    "\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        print(f\"Epoch {epoch+1:02d}/{10} | \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f} | Train IoU: {avg_train_iou:.4f} | Train Acc: {avg_train_acc:.4f} | \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f} | Val IoU: {avg_val_iou:.4f} | Val Acc: {avg_val_acc:.4f} | \"\n",
    "              f\"Time: {epoch_time:.1f}s\")\n",
    "\n",
    "    # Сохранение модели\n",
    "    model_path = \"house_segmentation_model.pth\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"\\nМодель успешно сохранена: {os.path.abspath(model_path)}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Инференс большой картинки (для Streamlit)\n",
    "# ----------------------------\n",
    "\n",
    "def predict_large_image(model_path, image_path, tile_size=512, device=\"cpu\"):\n",
    "    model = UNetResNet18(num_classes=1)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval().to(device)\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    h, w = img.shape[:2]\n",
    "    pred_mask = np.zeros((h, w), dtype=np.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for y in range(0, h, tile_size):\n",
    "            for x in range(0, w, tile_size):\n",
    "                y_end = min(y + tile_size, h)\n",
    "                x_end = min(x + tile_size, w)\n",
    "\n",
    "                tile = img[y:y_end, x:x_end]\n",
    "                pad_h = tile_size - tile.shape[0]\n",
    "                pad_w = tile_size - tile.shape[1]\n",
    "                tile_padded = np.pad(tile, ((0, pad_h), (0, pad_w), (0, 0)), mode='constant')\n",
    "                tile_tensor = torch.from_numpy(tile_padded).permute(2, 0, 1).float() / 255.0\n",
    "                tile_tensor = tile_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "                output = model(tile_tensor)\n",
    "                prob = torch.sigmoid(output).cpu().numpy()[0, 0]\n",
    "                prob = prob[:y_end - y, :x_end - x]\n",
    "                pred_mask[y:y_end, x:x_end] = prob\n",
    "\n",
    "    return (pred_mask > 0.5).astype(np.uint8) * 255  # Бинарная маска\n",
    "\n",
    "# ----------------------------\n",
    "# Запуск обучения (при необходимости)\n",
    "# ----------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_model()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c8771d-aa27-4cab-b3e8-cf0fe31753f1",
   "metadata": {},
   "source": [
    "Обучение проводилось в 4 эпохи и заняло около 3-х часов работы процессорного и GPU времени.\n",
    "Результаты получились удовлетворительные, в целом коррелирующие с лидербордом по данному датасету (https://project.inria.fr/aerialimagelabeling/leaderboard/)\n",
    "Val IoU: 0.7515 | Val Acc: 0.9619Val \n",
    "\n",
    "Рассчитанная модель сохранена в отдельный файл для дальнейшего использования в решении задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acce8e6-eb46-46af-95b0-7a498f90dabc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
